{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "152a1a82-137d-4da5-af4d-4b740d1e9a2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kkibet\\AppData\\Local\\Temp\\ipykernel_11872\\2452914223.py:7: DtypeWarning: Columns (6,7,8,10,15,16,17,18,19,21,24) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(file_path, encoding='latin1')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully read the file with encoding 'latin1'.\n",
      "                                              CATEGORY  Asset Count  \\\n",
      "0                                        1000-11090-10        29554   \n",
      "1                                        1000-12001-20        40841   \n",
      "2                                        1000-11099-30        81561   \n",
      "3    leasehold improvemnt-Leasehold Improvmnt.-GENERAL           55   \n",
      "4                                        1000-11002-20       161619   \n",
      "..                                                 ...          ...   \n",
      "114                                      1000-13099-30          101   \n",
      "115                                      1000-12004-20          183   \n",
      "116                                      3000-31000-20            4   \n",
      "117                                      1000-13005-10            2   \n",
      "118                                      4000-41000-20           31   \n",
      "\n",
      "       Total Cost     Total NBV  \n",
      "0    2.212343e+08  1.133399e+08  \n",
      "1    1.493506e+07  5.505230e+06  \n",
      "2    5.034672e+08  1.257066e+08  \n",
      "3    6.813289e+06  0.000000e+00  \n",
      "4    8.593740e+08  8.772865e+07  \n",
      "..            ...           ...  \n",
      "114  1.191511e+07  1.210858e+06  \n",
      "115  4.923855e+05  0.000000e+00  \n",
      "116  0.000000e+00  0.000000e+00  \n",
      "117  6.097500e+03  3.099580e+03  \n",
      "118  4.434827e+05  4.015920e+04  \n",
      "\n",
      "[119 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Assuming you have the dataset in a CSV file\n",
    "file_path = '3sn.csv'\n",
    "\n",
    "# Load the dataset\n",
    "df = pd.read_csv(file_path, encoding='latin1')\n",
    "print(\"Successfully read the file with encoding 'latin1'.\")\n",
    "\n",
    "# Replace 'Category', 'Cost', and 'NetBookValue' with the actual column names from your dataset\n",
    "category_column = 'CATEGORY'\n",
    "cost_column = 'COST'\n",
    "nbv_column = 'NBV'\n",
    "\n",
    "# Count the number of assets per category\n",
    "asset_count = df.groupby(category_column).size().reset_index(name='Asset Count')\n",
    "\n",
    "# Calculate the total cost per category\n",
    "total_cost = df.groupby(category_column)[cost_column].sum().reset_index(name='Total Cost')\n",
    "\n",
    "# Calculate the total NBV per category\n",
    "total_nbv = df.groupby(category_column)[nbv_column].sum().reset_index(name='Total NBV')\n",
    "\n",
    "# Merge the results into a single DataFrame\n",
    "result = asset_count.merge(total_cost, on=category_column).merge(total_nbv, on=category_column)\n",
    "\n",
    "# Fill missing categories with 0 if necessary\n",
    "all_categories = df[category_column].unique()\n",
    "result = result.set_index(category_column).reindex(all_categories, fill_value=0).reset_index()\n",
    "result.to_csv('3emptysn.CSV', index=False)\n",
    "print(result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3998959b-3d8f-4551-a1cd-4bc0dbd99175",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kkibet\\AppData\\Local\\Temp\\ipykernel_22132\\1415732256.py:6: DtypeWarning: Columns (6,7,8,10,15,16,17,18,19,21,24) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df2 = pd.read_csv(file_path, encoding='latin1')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                CATEGORY  1count_missing_serial_numbers\n",
      "0          1000-12001-20                          33863\n",
      "1         1000-11002.-10                          14916\n",
      "2          1000-12090-10                          68267\n",
      "3          1000-12001-10                          15515\n",
      "4    IT-Printers-GENERAL                              4\n",
      "..                   ...                            ...\n",
      "171        1000-18100-30                              2\n",
      "172       6000-62000.-10                              0\n",
      "173        4000-48300-30                              1\n",
      "174        5000-51000-50                              0\n",
      "175        1000-14004-10                              0\n",
      "\n",
      "[176 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "file_path = '1.csv'\n",
    "\n",
    "# Load the dataset\n",
    "df2 = pd.read_csv(file_path, encoding='latin1')\n",
    "\n",
    "# Step 2: Filter rows where SERIAL_NUMBER is missing (or empty)\n",
    "df_missing_serial = df2[df2['SERIAL_NUMBER'].isnull() | (df2['SERIAL_NUMBER'] == '')]\n",
    "\n",
    "# Step 3: Group by CATEGORY and count occurrences\n",
    "category_counts = df_missing_serial.groupby('CATEGORY').size()\n",
    "\n",
    "# Step 4: Reindex to include all categories, even those with count 0\n",
    "all_categories = df2['CATEGORY'].unique()\n",
    "category_counts = category_counts.reindex(all_categories, fill_value=0)\n",
    "\n",
    "# Step 5: Convert the Series to a DataFrame (optional)\n",
    "category_counts_df = category_counts.reset_index(name='1count_missing_serial_numbers')\n",
    "\n",
    "category_counts_df.to_csv('1c.CSV', index=False)\n",
    "\n",
    "print(category_counts_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ec78d884-2670-4d46-9952-4163c06e313f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kkibet\\AppData\\Local\\Temp\\ipykernel_11872\\3093565890.py:15: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  merged_df[col + '_file1'].fillna(0, inplace=True)\n",
      "C:\\Users\\kkibet\\AppData\\Local\\Temp\\ipykernel_11872\\3093565890.py:16: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  merged_df[col + '_file2'].fillna(0, inplace=True)\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'Asset Count_file3'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3805\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3804\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 3805\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine\u001b[38;5;241m.\u001b[39mget_loc(casted_key)\n\u001b[0;32m   3806\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[1;32mindex.pyx:167\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mindex.pyx:196\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\\\_libs\\\\hashtable_class_helper.pxi:7081\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\\\_libs\\\\hashtable_class_helper.pxi:7089\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'Asset Count_file3'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[13], line 17\u001b[0m\n\u001b[0;32m     15\u001b[0m         merged_df[col \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_file1\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mfillna(\u001b[38;5;241m0\u001b[39m, inplace\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m     16\u001b[0m         merged_df[col \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_file2\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mfillna(\u001b[38;5;241m0\u001b[39m, inplace\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m---> 17\u001b[0m         merged_df[col \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_file3\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mfillna(\u001b[38;5;241m0\u001b[39m, inplace\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m     18\u001b[0m         merged_df[col] \u001b[38;5;241m=\u001b[39m merged_df[[col \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_file1\u001b[39m\u001b[38;5;124m'\u001b[39m, col \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_file2\u001b[39m\u001b[38;5;124m'\u001b[39m, col \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_file3\u001b[39m\u001b[38;5;124m'\u001b[39m]]\u001b[38;5;241m.\u001b[39msum(axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m     20\u001b[0m \u001b[38;5;66;03m# Drop the individual file columns\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\frame.py:4102\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   4100\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m   4101\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[1;32m-> 4102\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mget_loc(key)\n\u001b[0;32m   4103\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[0;32m   4104\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3812\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3807\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(casted_key, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[0;32m   3808\u001b[0m         \u001b[38;5;28misinstance\u001b[39m(casted_key, abc\u001b[38;5;241m.\u001b[39mIterable)\n\u001b[0;32m   3809\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m casted_key)\n\u001b[0;32m   3810\u001b[0m     ):\n\u001b[0;32m   3811\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[1;32m-> 3812\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[0;32m   3813\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[0;32m   3814\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[0;32m   3815\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[0;32m   3816\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[0;32m   3817\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[1;31mKeyError\u001b[0m: 'Asset Count_file3'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the CSV files into pandas DataFrames\n",
    "df1 = pd.read_csv('3emptysn.csv', encoding='latin1')\n",
    "df2 = pd.read_csv('2emptysn.csv', encoding='latin1')\n",
    "df3 = pd.read_csv('1emptysn.csv', encoding='latin1')\n",
    "\n",
    "# Merge DataFrames on 'CATEGORY' column using outer join to include all categories\n",
    "merged_df = pd.merge(df1, df2, on='CATEGORY', how='outer', suffixes=('_file1', '_file2'))\n",
    "merged_df = pd.merge(merged_df, df3, on='CATEGORY', how='outer')\n",
    "\n",
    "# Fill NaN values with 0 for numerical columns\n",
    "for col in ['Asset Count', 'Total Cost', 'Total NBV']:\n",
    "    if col in merged_df.columns:\n",
    "        merged_df[col + '_file1'].fillna(0, inplace=True)\n",
    "        merged_df[col + '_file2'].fillna(0, inplace=True)\n",
    "        merged_df[col + '_file3'].fillna(0, inplace=True)\n",
    "        merged_df[col] = merged_df[[col + '_file1', col + '_file2', col + '_file3']].sum(axis=1)\n",
    "\n",
    "# Drop the individual file columns\n",
    "merged_df.drop(columns=[col + '_file1' for col in ['Asset Count', 'Total Cost', 'Total NBV']] +\n",
    "                              [col + '_file2' for col in ['Asset Count', 'Total Cost', 'Total NBV']] +\n",
    "                              [col + '_file3' for col in ['Asset Count', 'Total Cost', 'Total NBV']], inplace=True)\n",
    "\n",
    "# Save the merged DataFrame to a new CSV file\n",
    "merged_df.to_csv('merged_file.csv', index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "553aa861-04d0-4f41-b259-e81c298b9ff1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
